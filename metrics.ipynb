{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(iris.feature_names)\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression without scaling, grid search, hyperparameter tuning, and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n",
      "0.06666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnbjohn/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(\n",
    "  logreg.score(X_test, y_test)\n",
    ")\n",
    "\n",
    "print(\n",
    "  mean_squared_error(y_pred, y_test)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with scaling, but without grid search, hyperparameter tuning, and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9111111111111111\n",
      "MSE: 0.08888888888888889\n",
      "RMSE: 0.29814239699997197\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "\n",
    "y_score = logreg.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"Accuracy: {y_score}\")\n",
    "print(f\"MSE: {mean_squared_error(y_pred, y_test)}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_pred, y_test))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with scaling and grid search, but without hyperparameter tuning and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: [1.         0.96666667 0.93333333 0.93333333 0.96666667]\n",
      "Average accuracy: 0.9600000000000002\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle = True, random_state=42)\n",
    "logreg_kf_score = cross_val_score(logreg, X_scaled, y, cv = kf)\n",
    "\n",
    "print(f\"Accuracies: {logreg_kf_score}\")\n",
    "print(f\"Average accuracy: {np.mean(logreg_kf_score)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with scaling, grid search, and hyperparameter tuning, but without pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'tol': 0.16631578947368422, 'solver': 'newton-cg', 'class_weight': 'balanced', 'C': 0.4268421052631579}\n",
      "Tuned Logistic Regression Best Accuracy Score: 0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "logreg_params = {\n",
    "  \"tol\": np.linspace(0.01, 1.0, 20),\n",
    "  \"C\": np.linspace(0.01, 1.0, 20),\n",
    "  \"class_weight\": [\"balanced\", {0:0.8, 1:0.2}],\n",
    "  \"solver\": [\"newton-cg\", \"newton-cholesky\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "}\n",
    "\n",
    "logreg_cv = RandomizedSearchCV(logreg, logreg_params, cv = kf)\n",
    "logreg_cv.fit(X_scaled, y)\n",
    "\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Best Accuracy Score: {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.11111111111111\n"
     ]
    }
   ],
   "source": [
    "steps = [\n",
    "  (\n",
    "    \"standardization\",\n",
    "    StandardScaler()\n",
    "  ),\n",
    "  (\n",
    "    \"logistic_regression\",\n",
    "    LogisticRegression(\n",
    "      tol = 0.16631578947368422,\n",
    "      solver = \"newton-cg\",\n",
    "      class_weight = \"balanced\",\n",
    "      C = 0.4268421052631579\n",
    "    )\n",
    "  )\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps=steps)\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "y_pred = pipeline.predict(X_test_scaled)\n",
    "r2_score = pipeline.score(X_test_scaled, y_test)\n",
    "\n",
    "correct_predictions = (y_pred == y_test)\n",
    "correct_percentage = (sum(correct_predictions) / len(y_test)) * 100\n",
    "print(correct_percentage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are classifiying the data, so `pipeline.score(...)` will return the accuracy of the model. Unlike regression models, use `pipeline.r2_score(...)` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.82      0.93      0.87        15\n",
      "           2       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.92      0.91      0.91        45\n",
      "weighted avg       0.92      0.91      0.91        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Classification report: {classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
